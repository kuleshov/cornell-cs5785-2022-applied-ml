{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_f5u2x9nn6I",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/cornell_tech2.svg\"></left>\n",
    "\n",
    "# Lecture 19: Introduction to LLMs\n",
    "\n",
    "### Applied Machine Learning\n",
    "\n",
    "__Brandon Amos__<br>Cornell Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np; np.set_printoptions(precision=2)\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.figsize'] = [12, 4]\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "device = 'mps'\n",
    "\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preface and disclaimer ⚠\n",
    "\n",
    "+ Language, NLP, LLMs is a huge space. Many great resources out there!\n",
    "+ **This lecture**\n",
    "    1. Tour through my favorite introductory parts from them\n",
    "    2. Some code examples to show how to apply and use <br/>\n",
    "       a) **basic tokenization** and **autoregressive generation**, <br/>\n",
    "       b) **chat templates**, and <br/>\n",
    "       c) **code completion** (fill-in-the-middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformers and language models: ubiquitous\n",
    "\n",
    "<center>\n",
    "<img width='55%' src=\"https://www.comet.com/site/wp-content/uploads/2023/07/Screen-Shot-2023-07-11-at-9.48.50-PM-1536x1153.png\"/><br/>\n",
    "<a href=\"https://www.comet.com/site/blog/explainable-ai-for-transformers/\">Image sources: Explainable AI: Visualizing Attention in Transformers</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review on classification\n",
    "\n",
    "$$ \\underbrace{\\text{Dataset}}_\\text{Features, Attributes, Targets} + \\underbrace{\\text{Learning Algorithm}}_\\text{Model Class + Objective + Optimizer } \\to \\text{Predictive Model} $$\n",
    "\n",
    "-----\n",
    "\n",
    "1. Training dataset $\\mathcal{D} = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\ldots, (x^{(N)}, y^{(N)})\\}$.\n",
    "2. The target space is discrete: $\\mathcal{Y} = \\{y_1, y_2, \\ldots y_K\\}$. <br>\n",
    "   <span style='color: gray'>Each of the $K$ discrete values corresponds to a <em>class</em> that we want to predict</span>\n",
    "3. Optimize the conditional likelihood\n",
    "    $$\\max_\\theta \\ell(\\theta) = \\max_{\\theta} \\frac{1}{N}\\sum_{i=1}^N \\log P_\\theta(y^{(i)} | {x}^{(i)}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LLMs (for generation) are \"just\" doing next-token classification\n",
    "\n",
    "+ Represent language as a sequence of **discrete tokens**\n",
    "+ Given the past sequence of text $x^{(i)}$, classify the next portion $y{(i)}$.\n",
    "+ Parameterize $P_\\theta$ with a sequence architecture (e.g., a transformer)\n",
    "+ (Pre)train with maximum likelihood\n",
    "  $$\\max_\\theta \\ell(\\theta) = \\max_{\\theta} \\frac{1}{N}\\sum_{i=1}^N \\log P_\\theta(y^{(i)} | {x}^{(i)}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization and representing language\n",
    "\n",
    "+ **Tokenization** is how the string is represented <span style='color: grey'>(what the $K$ values correspond to)</span>\n",
    "+ Dataset has token strings $x^{(i)}\\in\\{1, \\ldots, K\\}^{n_i}$\n",
    "  and next tokens $y^{(i)}\\in\\{1, \\ldots, K\\}$:\n",
    "  $$\\mathcal{D} = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\ldots, (x^{(N)}, y^{(N)})\\}$$\n",
    "+ Many options for how to tokenize a sequence, e.g.:\n",
    "\n",
    "<center>\n",
    "<img width='25%' src='https://njoroge.tomorrow.co.ke/static/images/AI/tokenization.jpg'/><br/>\n",
    "\n",
    "Image source: \n",
    "<a href=\"https://njoroge.tomorrow.co.ke/blog/ai/word_vs_character_level_tokenization\">Character vs. Word Tokenization in NLP</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization in practice\n",
    "\n",
    "+ A large topic and very important choice\n",
    "+ Tokens often learned via Byte-Pair Encoding, SentencePiece, or WordPiece\n",
    "+ Many other great resources:\n",
    "  + [HuggingFace Tokenizer Summary](https://huggingface.co/docs/transformers/en/tokenizer_summary)\n",
    "  + [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE) ([code](https://github.com/karpathy/minbpe))\n",
    "  + [Llama tokenizer visualizer](https://belladoreai.github.io/llama-tokenizer-js/example-demo/build/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applications of transformers\n",
    "\n",
    "<img src=\"https://www.comet.com/site/wp-content/uploads/2023/07/Screen-Shot-2023-07-13-at-6.37.03-PM.png\"/>\n",
    "<center><a href=\"https://www.comet.com/site/blog/explainable-ai-for-transformers/\">Image source: Explainable AI: Visualizing Attention in Transformers</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What attention looks like\n",
    "\n",
    "<center>\n",
    "<img width='55%' src=\"https://sebastianraschka.com/images/blog/2023/self-attention-from-scratch/summary.png\"> <br/>\n",
    "\n",
    "<small><a href=\"https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html\">Source: Understanding and Coding the Self-Attention Mechanism of LLMs From Scratch</a></small>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Putting everything together\n",
    "\n",
    "<center>\n",
    "<img width='70%' src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd8bc0b7-e7b7-4a96-9e00-627ad2ecda20_2232x1362.png\"/> <br>\n",
    "(Source: the Llama 2 paper)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Full architectures\n",
    "\n",
    "Combine many components we've covered: embeddings, attention, residual\n",
    "\n",
    "<center>\n",
    "<img width='60%' src=\"https://media.licdn.com/dms/image/v2/D5612AQGzmd6t0QZpcw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1710740975319?e=1736985600&v=beta&t=a-hzk4nmEQCMeKYfX7miID0veRX8AwM4Hd6dxF9qPOo\"/> <br/>\n",
    "Image source: <a href=\"https://www.youtube.com/@umarjamilai\">Umar Jamil</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Going deeper into the architecture\n",
    "\n",
    "+ Many other interesting design choices we won't cover, especially positional embeddings, masking, KV caching, flash attention\n",
    "+ Some further reading:\n",
    "    + [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "    + [Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)\n",
    "    + [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "    + [Explained: Multi-head Attention](https://storrs.io/attention/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Going even deeper into the training setup \n",
    "\n",
    "Maximum likelihood (pre)training is just the beginning...\n",
    "+ Alignment, supervised fine-tuning, preference optimization, RLHF, tool use\n",
    "\n",
    "<center>\n",
    "<img width='75%' src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb9d0144-3952-42db-8382-8e2eb37d917e_1670x640.png\">\n",
    "</center>\n",
    "\n",
    "<center>Image source: <a href=\"https://arxiv.org/abs/2203.02155\">InstructGPT</a> (and <a href=\"https://cameronrwolfe.substack.com/p/understanding-and-using-supervised\">here</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/cornell_tech2.svg\"></left>\n",
    "\n",
    "# Part 2: Running some code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loading a model and tokenizer\n",
    "\n",
    "+ [HuggingFace](https://huggingface.co/) hosts many models, tokenizers, datasets, and benchmarks\n",
    "and provides Python/PyTorch libraries for downloading and using them\n",
    "+ Let's load a \"small\" (with 1B parameters) Llama 3.2 model. (It runs on my laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's start with the tokenizer. What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='meta-llama/Llama-3.2-1B-Instruct', vocab_size=128000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128005: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128011: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128012: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128013: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128014: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128015: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128016: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128017: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128018: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128019: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128020: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128021: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128022: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128023: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128024: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128025: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128026: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128027: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128028: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128029: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128030: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128031: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128032: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128033: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128034: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128035: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128036: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128037: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128038: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128039: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128040: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128041: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128042: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128043: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128044: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128045: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128046: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128047: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128048: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128049: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128050: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128051: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128052: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128053: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128054: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128055: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128056: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128057: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128058: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128059: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128060: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128061: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128062: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128063: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128064: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128065: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128066: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128067: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128068: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128069: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128070: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128071: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128072: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128073: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128074: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128075: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128076: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128077: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128078: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128079: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128080: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128081: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128082: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128083: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128084: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128085: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128086: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128087: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128088: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128089: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128090: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128091: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128092: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128093: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128094: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128095: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128096: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128097: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128098: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128099: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128100: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128101: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128102: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128103: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128104: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128105: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128106: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128107: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128108: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128109: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128110: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128111: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128112: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128113: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128114: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128115: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128116: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128117: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128118: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128119: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128120: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128121: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128122: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128123: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128124: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128125: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128126: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128127: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128128: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128129: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128130: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128131: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128132: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128133: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128134: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128135: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128136: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128137: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128138: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128139: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128140: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128141: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128142: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128143: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128144: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128145: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128146: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128147: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128148: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128149: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128150: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128151: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128152: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128153: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128154: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128155: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128156: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128157: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128158: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128159: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128160: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128161: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128162: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128163: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128164: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128165: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128166: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128167: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128168: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128169: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128170: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128171: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128172: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128173: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128174: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128175: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128176: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128177: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128178: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128179: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128180: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128181: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128182: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128183: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128184: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128185: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128186: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128187: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128188: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128189: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128190: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128191: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128192: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128193: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128194: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128195: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128196: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128197: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128198: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128199: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128200: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128201: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128202: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128203: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128204: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128205: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128206: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128207: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128208: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128209: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128210: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128211: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128212: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128213: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128214: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128215: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128216: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128217: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128218: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128219: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128220: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128221: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128222: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128223: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128224: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128225: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128226: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128227: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128228: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128229: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128230: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128231: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128232: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128233: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128234: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128235: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128236: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128237: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128238: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128239: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128240: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128241: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128242: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128243: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128244: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128245: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128246: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128247: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128248: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128249: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128250: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128251: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128252: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128253: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128254: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128255: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's check the vocabulary\n",
    "<span style='color: grey'>(Ġ is special and indicates a space before the word)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bilt': 70824,\n",
       " 'ĠãĤŃ': 109949,\n",
       " 'ucus': 38601,\n",
       " '_depth': 19601,\n",
       " 'ç·Ĵ': 114262,\n",
       " 'ĠSimilarly': 35339,\n",
       " 'Ġtess': 80930,\n",
       " 'Ġspecials': 60874,\n",
       " 'ĠOT': 8775,\n",
       " '=j': 46712,\n",
       " 'ylation': 79933,\n",
       " 'ĠNose': 93223,\n",
       " 'ĠRolls': 70710,\n",
       " '.Power': 55186,\n",
       " '.Wh': 18951,\n",
       " 'åĪ©çĶ¨': 107740,\n",
       " 'ĠATT': 42385,\n",
       " 'Ġraj': 92528,\n",
       " 'OLLOW': 31289,\n",
       " 'ĠBeer': 34484,\n",
       " '--------------------------------': 1434,\n",
       " 'ĠØ§ÙĦØªÙĪ': 124487,\n",
       " 'Almost': 39782,\n",
       " 'è§Ĵèī²': 125499,\n",
       " 'ĠÙĨØ²Ø¯ÛĮÚ©': 121045,\n",
       " '-f': 2269,\n",
       " 'è¨ĺäºĭ': 77219,\n",
       " 'Visibility': 11686,\n",
       " 'ëĮĢë¡ľ': 106687,\n",
       " 'ĠRather': 26848,\n",
       " 'ÂłT': 115414,\n",
       " 'Ġdescribes': 16964,\n",
       " 'Ġpouvoir': 68226,\n",
       " 'dimensions': 60339,\n",
       " 'umbling': 42732,\n",
       " 'Ġsimult': 20731,\n",
       " '[],': 13292,\n",
       " \"('');Ċ\": 21011,\n",
       " 'Ġnaturally': 18182,\n",
       " 'ĠÐŁÐ°Ð²': 114087,\n",
       " 'Ġ:|:': 114168,\n",
       " 'Ġtreatments': 22972,\n",
       " 'hait': 98808,\n",
       " 'Ð²ÐµÐ´': 36750,\n",
       " 'ĠFold': 61573,\n",
       " 'á»ĥn': 87982,\n",
       " 'Ġspis': 123099,\n",
       " 'Ġmales': 25000,\n",
       " '(Q': 6386,\n",
       " 'orient': 15226,\n",
       " 'Ġimgs': 57265,\n",
       " '.executeUpdate': 40012,\n",
       " 'Ġbooked': 34070,\n",
       " '>::': 6974,\n",
       " 'Ġdisappear': 32153,\n",
       " '_ALIGN': 37788,\n",
       " '-complete': 75514,\n",
       " '$pdf': 35310,\n",
       " 'Ġsalmon': 41420,\n",
       " 'PLIT': 52697,\n",
       " 'ĠMarketing': 18729,\n",
       " '.getD': 98558,\n",
       " \"'.ĊĊ\": 30736,\n",
       " 'bam': 81667,\n",
       " 'Ġseals': 57877,\n",
       " '_letters': 68430,\n",
       " 'assertEquals': 16827,\n",
       " '.rotation': 24136,\n",
       " 'ĠWindowManager': 78855,\n",
       " 'Ġremain': 7293,\n",
       " 'Participant': 68604,\n",
       " '293': 17313,\n",
       " 'Contours': 89814,\n",
       " 'ilde': 35376,\n",
       " '.serializer': 80535,\n",
       " 'ĠvhodnÃ©': 126631,\n",
       " 'ĠÑģÐ°Ð¼ÑĭÐ¼': 124704,\n",
       " 'Students': 32052,\n",
       " 'Ġdolor': 24578,\n",
       " '_VAL': 6224,\n",
       " 'ÙħØ§': 100653,\n",
       " 'xaf': 55895,\n",
       " 'extracomment': 76613,\n",
       " 'categoria': 44344,\n",
       " '&,': 32763,\n",
       " 'âĢľOne': 99799,\n",
       " 'ãĢĤ': 1811,\n",
       " '(fs': 32956,\n",
       " 'ĉbit': 81080,\n",
       " 'Ġfrench': 42293,\n",
       " 'asyonu': 114853,\n",
       " 'ieren': 16414,\n",
       " '.Assign': 88071,\n",
       " '_modules': 16227,\n",
       " 'ĠWW': 29144,\n",
       " 'Ġà¸ŀà¸£à¸°': 107460,\n",
       " '_forms': 65382,\n",
       " 'ÑĩÐµÑģ': 100925,\n",
       " 'ĠDerby': 46873,\n",
       " 'acker': 9881,\n",
       " '.BorderSize': 73881,\n",
       " 'ĠBolton': 62677,\n",
       " 'ĠStrike': 36478,\n",
       " 'ĠØ¢ÙĤØ§ÛĮ': 117792,\n",
       " 'é©': 77180,\n",
       " 'ĠSoviet': 19953,\n",
       " 'Ġpope': 64372,\n",
       " 'ĠÐ´ÑĢÑĥÐ³Ð¾Ð¹': 113539,\n",
       " 'episode': 40391,\n",
       " 'Ġazt': 98994,\n",
       " '/apis': 67252,\n",
       " 'Ð¸ÑĤÐµÐ»ÑĮÐ½Ð¾Ð³Ð¾': 118059,\n",
       " \"'hui\": 88253,\n",
       " '.fromFunction': 87268,\n",
       " '_CUSTOMER': 91392,\n",
       " 'ursor': 3908,\n",
       " 'ìĥµ': 110145,\n",
       " 'ĠFirstName': 50567,\n",
       " 'ĠParenthood': 50265,\n",
       " 'Ġstale': 51451,\n",
       " '=u': 39733,\n",
       " 'Ġucz': 88526,\n",
       " 'ĠonCreateView': 42538,\n",
       " 'AnimationsModule': 65279,\n",
       " 'stocks': 69127,\n",
       " 'å®¤': 102452,\n",
       " 'ĠDress': 29318,\n",
       " '27': 1544,\n",
       " 'Ġbicycles': 73961,\n",
       " 'Ġfigsize': 79201,\n",
       " 'ĠtanÄ±m': 108445,\n",
       " 'Ð¾Ð´Ñĥ': 106946,\n",
       " 'ftp': 26124,\n",
       " 'ĠÛĮÙĪØªÛĮ': 121510,\n",
       " 'ĠBat': 16488,\n",
       " 'ĠSEP': 74869,\n",
       " 'Ġkarar': 104333,\n",
       " 'ĠRajasthan': 87440,\n",
       " 'icator': 13557,\n",
       " 'oon': 9186,\n",
       " 'ĠLal': 84883,\n",
       " 'ĠPractical': 66736,\n",
       " '/pass': 68170,\n",
       " 'ĠWinn': 41631,\n",
       " 'Ġautomobile': 35528,\n",
       " 'čĊčĊčĊ': 8731,\n",
       " 'Ø´Ùģ': 110941,\n",
       " 'Î¬ÏģÏĩ': 113192,\n",
       " 'Ġhates': 55406,\n",
       " 'ĠTops': 93505,\n",
       " 'ALLY': 29555,\n",
       " '_train': 7745,\n",
       " 'Ġkil': 15395,\n",
       " 'ĠUNC': 76355,\n",
       " '(routes': 45988,\n",
       " '(defvar': 90485,\n",
       " '_REL': 42307,\n",
       " 'ND': 8225,\n",
       " 'profiles': 57295,\n",
       " 'os': 437,\n",
       " 'Ġìĺģ': 101603,\n",
       " '.report': 23616,\n",
       " 'Tan': 77197,\n",
       " 'opped': 18033,\n",
       " 'pis': 57996,\n",
       " '_ACK': 51790,\n",
       " 'å¥ª': 127696,\n",
       " 'æł·åŃĲ': 124098,\n",
       " 'ĠCitizenship': 94836,\n",
       " 'Ġhooked': 43770,\n",
       " '),': 705,\n",
       " 'Ġnos': 12155,\n",
       " 'ĠÚ¯Ø±Ø¯': 104027,\n",
       " 'Ġtowering': 87794,\n",
       " 'Ġtypings': 25966,\n",
       " 'ĠëĪĦ': 106200,\n",
       " 'à¹Īà¸²à¸ĩ': 100957,\n",
       " ')\");ĊĊ': 67471,\n",
       " \"/')Ċ\": 49274,\n",
       " 'ä»¬': 80578,\n",
       " 'masÄ±na': 105878,\n",
       " '.transforms': 87407,\n",
       " 'Ġaplikace': 125481,\n",
       " 'Ġglove': 56520,\n",
       " 'Ġãģ«': 106004,\n",
       " 'ĠallowNull': 42540,\n",
       " 'ĸìĹĲ': 122226,\n",
       " 'à¤Ĥà¤ªà¤¨': 108500,\n",
       " 'ĠHue': 67051,\n",
       " 'ĠÃ§ift': 114537,\n",
       " 'Ø§ÙĨØ¯': 101756,\n",
       " 'ĠÐ·Ð½Ð°ÑĩÐµÐ½Ð½Ñı': 116884,\n",
       " 'ĠÑĪÐ¸ÑĢ': 108205,\n",
       " 'ä»»åĬ¡': 89902,\n",
       " 'angi': 79428,\n",
       " 'Ġà¤ªà¤¢': 111354,\n",
       " 'ĠSavior': 77046,\n",
       " 'Ġmercenaries': 99687,\n",
       " 'Ġ{}:': 92012,\n",
       " 'ĠRTWF': 63785,\n",
       " '_boolean': 47742,\n",
       " 'Ġhire': 18467,\n",
       " 'I': 40,\n",
       " 'á»ĵn': 103290,\n",
       " '(jq': 97987,\n",
       " 'ĉĉĉĉĉĉĉĉĠĠ': 71677,\n",
       " 'Ġadditives': 85286,\n",
       " 'Ġbesoin': 63669,\n",
       " 'ĠRecap': 99134,\n",
       " \"Ġ'&'\": 86199,\n",
       " 'mite': 53995,\n",
       " 'ĠÃ©s': 22257,\n",
       " 'ĠSculpt': 83797,\n",
       " 'marshal': 28220,\n",
       " 'Ġvtx': 97979,\n",
       " 'Ġshowcase': 35883,\n",
       " 'ĠHeads': 71607,\n",
       " '][\"': 10069,\n",
       " 'Ġ)čĊ': 8786,\n",
       " 'Ġword': 3492,\n",
       " 'Ġbox': 3830,\n",
       " 'ĠMus': 5444,\n",
       " 'Ġhalted': 61195,\n",
       " 'Watching': 96837,\n",
       " 'kas': 63999,\n",
       " 'æłªå¼ıä¼ļç¤¾': 121450,\n",
       " 'Ġcampaigners': 94393,\n",
       " 'Jump': 35079,\n",
       " 'Ġcited': 22628,\n",
       " 'Ġclassified': 21771,\n",
       " 'Ġrealization': 49803,\n",
       " 'Ġwaypoint': 66276,\n",
       " 'executable': 97024,\n",
       " 'Ġvorhand': 93770,\n",
       " 'punkt': 72965,\n",
       " 'Ġipsum': 27439,\n",
       " 'Administrator': 63476,\n",
       " 'Ġadres': 66861,\n",
       " '.Points': 90370,\n",
       " 'ĠBroadcom': 97017,\n",
       " 'ãĢĤãĢĤĊĊ': 54689,\n",
       " 'ĠConcurrent': 43804,\n",
       " 'Ġbast': 33077,\n",
       " 'ĠBK': 77882,\n",
       " 'ìĽĲ': 55421,\n",
       " 'ĠDataset': 40283,\n",
       " 'ĠRADIO': 83260,\n",
       " 'ãĤĮãģŁ': 103468,\n",
       " 'ĠHexatrigesimal': 79740,\n",
       " ':\\\\/\\\\/': 15685,\n",
       " 'immer': 19519,\n",
       " 'PER': 9851,\n",
       " '_sampling': 78816,\n",
       " 'ĠåĽ½': 103774,\n",
       " '.Photo': 73199,\n",
       " 'Ġborrower': 70719,\n",
       " '(age': 67695,\n",
       " 'Â¯Â¯Â¯Â¯': 62807,\n",
       " 'InputDialog': 93937,\n",
       " 'ĠGerard': 82218,\n",
       " 'Slug': 56068,\n",
       " 'ĉaddr': 54283,\n",
       " 'ĠdÃ©s': 46838,\n",
       " 'Ġvak': 75925,\n",
       " 'Ġefficiency': 15374,\n",
       " 'Ġnewly': 13945,\n",
       " 'oundary': 73566,\n",
       " 'Ġcognition': 75310,\n",
       " 'Ġstrap': 34647,\n",
       " 'ĠÑĸÑģÐ½Ñĥ': 115439,\n",
       " 'ĠzveÅĻej': 126769,\n",
       " '428': 19140,\n",
       " 'ÏĨÎŃ': 112404,\n",
       " '!\",': 19318,\n",
       " 'Mutation': 55098,\n",
       " '\";}Ċ': 66643,\n",
       " 'Ġbuzz': 31527,\n",
       " '-strong': 96857,\n",
       " 'ĠRandomForest': 91814,\n",
       " 'Ġfilepath': 27146,\n",
       " 'Ġtimer': 9198,\n",
       " 'Ġfacet': 45607,\n",
       " 'ĠÐ¿ÑĢÐ¾Ð´Ð¾Ð»Ð¶': 111119,\n",
       " 'Ø¹ÙĦÙĤ': 123260,\n",
       " 'SIG': 51731,\n",
       " 'attention': 54203,\n",
       " '());čĊ': 6333,\n",
       " '130': 5894,\n",
       " 'Ġtecn': 41934,\n",
       " 'ommen': 47746,\n",
       " 'uous': 9373,\n",
       " 'implify': 71306,\n",
       " 'ĠSan': 5960,\n",
       " 'ØªÙģ': 106031,\n",
       " 'Ġrightly': 54466,\n",
       " '(optimizer': 86594,\n",
       " 'ostat': 109524,\n",
       " 'Ġëĭ¤ìĸĳíķľ': 118696,\n",
       " 'Ġcoil': 40760,\n",
       " 'Ð»Ð¾Ð¼': 105563,\n",
       " '.PNG': 95401,\n",
       " 'UNIT': 23909,\n",
       " '\\\\Api': 36917,\n",
       " 'shown': 70463,\n",
       " 'ÑĤÐ¾Ð¼': 94866,\n",
       " 'ĠMexicans': 97862,\n",
       " 'ĠUh': 69149,\n",
       " 'ĠÑĤÑĢÑĥÐ´Ð°': 123691,\n",
       " 'à¤¾à¤ĸ': 104278,\n",
       " 'ĠPek': 127146,\n",
       " 'Ġlistener': 11700,\n",
       " '526': 22593,\n",
       " 'Ġselenium': 37045,\n",
       " 'ĠSUM': 31835,\n",
       " 'ĠWild': 13944,\n",
       " 'Ġtháº£i': 119332,\n",
       " 'Separator': 16814,\n",
       " 'Ġdrunk': 29850,\n",
       " 'support': 24249,\n",
       " 'é¦Ļ': 102765,\n",
       " 'usi': 53913,\n",
       " 'iens': 80463,\n",
       " 'Û±Ûµ': 109555,\n",
       " 'ĠMandela': 88430,\n",
       " 'Ġtelevised': 76710,\n",
       " 'TM': 22809,\n",
       " 'Ġfund': 3887,\n",
       " 'ĠSavage': 54036,\n",
       " \"')==\": 99991,\n",
       " 'eyer': 35472,\n",
       " 'ĠPhilippe': 67954,\n",
       " 'áº¯n': 102675,\n",
       " 'ĠÙĦÛĮ': 109378,\n",
       " 'Ġschwar': 82928,\n",
       " 'Binder': 45155,\n",
       " 'ÑĨÑĸÑİ': 103781,\n",
       " '.JScrollPane': 63928,\n",
       " '.sub': 4407,\n",
       " 'âĢĶfrom': 88958,\n",
       " '.resize': 17838,\n",
       " 'ĠRak': 69892,\n",
       " 'ĠÐ²ÑģÑı': 111454,\n",
       " 'å¼ĺ': 119219,\n",
       " 'ĠShea': 86068,\n",
       " 'ï¼ĮåĪĻ': 96153,\n",
       " 'Ġdecorators': 63778,\n",
       " 'uja': 89808,\n",
       " 'Ġfeud': 57810,\n",
       " 'Ġstab': 28062,\n",
       " 'ê´Ģê³Ħ': 126951,\n",
       " 'Ġlá»£i': 104033,\n",
       " 'ĠDescription': 7817,\n",
       " '/ui': 23252,\n",
       " 'ĠZac': 92746,\n",
       " 'ĠdÄ±ÅŁÄ±': 120748,\n",
       " '(Global': 47844,\n",
       " 'Europe': 31880,\n",
       " 'Ġ&(': 23639,\n",
       " 'ĠOM': 48437,\n",
       " '.records': 65616,\n",
       " '.Orders': 88027,\n",
       " 'Ð¾ÑģÐ¾ÑĦ': 113822,\n",
       " 'chin': 60171,\n",
       " 'Ġadvisor': 37713,\n",
       " 'ĠÐ¾Ð±Ð»': 124161,\n",
       " '.datasets': 59252,\n",
       " '.ĊĊĊĊ': 2055,\n",
       " 'Ġstable': 15528,\n",
       " 'Ghost': 65786,\n",
       " 'Ã¡vÃ¡nÃŃ': 106832,\n",
       " 'Ġentitled': 20458,\n",
       " 'Ġdistinctions': 87259,\n",
       " 'AssignableFrom': 66785,\n",
       " 'CLA': 42235,\n",
       " 'ĠÏĢÎ¬': 119779,\n",
       " 'ÂłÂłÂłÂłÂłÂł': 110029,\n",
       " 'Ġtide': 43038,\n",
       " 'Ġvary': 13592,\n",
       " 'Ġà¤ĩà¤ķ': 123219,\n",
       " '(players': 72339,\n",
       " 'ĠGenerator': 29458,\n",
       " 'utherford': 94094,\n",
       " 'Ġpoids': 97418,\n",
       " 'íĥĢ': 101109,\n",
       " 'ĉcontrol': 83886,\n",
       " 'drop': 6861,\n",
       " 'ĠBarn': 23229,\n",
       " 'Ġdatetime': 9050,\n",
       " 'xd': 9902,\n",
       " 'ĠØ¨ÛĮØ±ÙĪÙĨ': 110785,\n",
       " 'ĠOwen': 47809,\n",
       " 'hydration': 81824,\n",
       " 'ĠDowntown': 44985,\n",
       " 'Activated': 72458,\n",
       " 'Ð½ÐµÐ¼Ñĥ': 127536,\n",
       " 'ĠBlend': 55248,\n",
       " '.arch': 39191,\n",
       " 'Ġelimin': 38416,\n",
       " 'ĠInnoc': 84593,\n",
       " 'ĠHtmlWebpackPlugin': 93515,\n",
       " 'Ġreality': 8903,\n",
       " ']);ĊĊ': 10359,\n",
       " \"Ġ('\\\\\": 89844,\n",
       " 'Ġolay': 107633,\n",
       " 'Î´Î¿ÏĤ': 114132,\n",
       " 'ĠNarrow': 83411,\n",
       " 'Auto': 13556,\n",
       " 'Ġmesel': 123790,\n",
       " 'homes': 86372,\n",
       " 'Ġfiltering': 30770,\n",
       " 'ĠÐ·Ð´': 101384,\n",
       " 'ĠÙħØŃØ¯ÙĪØ¯': 112911,\n",
       " 'Ġpoder': 29638,\n",
       " 'ĠÑģÐ¾Ð²ÑĢÐµÐ¼': 113506,\n",
       " 'uer': 8977,\n",
       " 'Liver': 83995,\n",
       " 'Ġlivest': 42912,\n",
       " 'xr': 52097,\n",
       " '_button': 8655,\n",
       " 'ØªÙĬ': 102044,\n",
       " 'ç»ľ': 69165,\n",
       " 'CRC': 84439,\n",
       " 'ĠsociÃ¡lnÃŃ': 120934,\n",
       " '-xs': 10144,\n",
       " 'Ġvampire': 51587,\n",
       " 'Ġbe': 387,\n",
       " '_course': 32826,\n",
       " '.RunWith': 53537,\n",
       " 'Ġexploitation': 40761,\n",
       " 'Ã¤nn': 64068,\n",
       " 'osemite': 84113,\n",
       " 'Ã¡nt': 86533,\n",
       " 'ĠNSString': 9519,\n",
       " 'Ġformula': 15150,\n",
       " 'Ġharvested': 67572,\n",
       " 'Ġstadiums': 90184,\n",
       " 'ĠResp': 80886,\n",
       " ']-->Ċ': 55869,\n",
       " 'ÎĻÎŁÎ¥': 111701,\n",
       " 'Ġridic': 20561,\n",
       " 'ĠÅŁek': 94395,\n",
       " 'à¸Ńà¸²à¸ģà¸²à¸¨': 115852,\n",
       " 'GUID': 42878,\n",
       " 'ĠØ§ÙĬ': 101870,\n",
       " '].': 948,\n",
       " 'Ġà¸£à¸²à¸Ħ': 124637,\n",
       " '.ConnectionStrings': 80211,\n",
       " 'Ġgrinding': 17282,\n",
       " 'ÙĨÛĮÙĨ': 104104,\n",
       " 'ATIC': 47459,\n",
       " '(\"\\\\': 5026,\n",
       " 'à¹Īà¸Ĺ': 115460,\n",
       " 'Attention': 70429,\n",
       " 'ĠIhrem': 78165,\n",
       " 'Ġregistered': 9879,\n",
       " 'Ġaaa': 84565,\n",
       " 'Ġcardiovascular': 41713,\n",
       " 'Od': 67408,\n",
       " '_defined': 53970,\n",
       " 'cite': 68175,\n",
       " 'lse': 88882,\n",
       " 'ãĤ¨': 76739,\n",
       " '.getC': 23308,\n",
       " 'Ġsiyaset': 124419,\n",
       " 'Difference': 63807,\n",
       " 'Ġhealthy': 9498,\n",
       " 'Ġscaling': 28041,\n",
       " 'coni': 86310,\n",
       " 'hover': 18043,\n",
       " 'Ġoctave': 75032,\n",
       " 'Ġseat': 10954,\n",
       " 'Ġ_____': 66992,\n",
       " 'Ġfanatic': 97899,\n",
       " 'Ġtheor': 46820,\n",
       " 'ĠDiego': 18842,\n",
       " 'ĠRussell': 25953,\n",
       " 'Ġ\\\\`': 96647,\n",
       " 'Ġanywhere': 12660,\n",
       " 'Ġrecruitment': 34102,\n",
       " 'ĠDou': 17440,\n",
       " 'lÃŃ': 101061,\n",
       " '(models': 20905,\n",
       " 'Ġviral': 29962,\n",
       " 'Ġtogg': 54906,\n",
       " 'Ġgaining': 30240,\n",
       " '_lookup': 28564,\n",
       " 'Ø¯ÛĮØ¯': 111944,\n",
       " 'ĠëĦ': 66653,\n",
       " 'ĠHam': 9777,\n",
       " 'ĠFraser': 56230,\n",
       " '_countries': 92774,\n",
       " '(Device': 74516,\n",
       " 'NotFoundException': 14920,\n",
       " 'ĠWEB': 45056,\n",
       " 'ÑĢÐ¾Ð²Ð°ÑĤÑĮ': 105727,\n",
       " 'maj': 96295,\n",
       " 'Ġwrongful': 93732,\n",
       " 'Ġmysterious': 26454,\n",
       " 'Ġmaturity': 48261,\n",
       " 'Ġatoms': 33299,\n",
       " ':left': 35910,\n",
       " 'ĠØªÚ©': 108345,\n",
       " 'Ġlash': 98381,\n",
       " 'ĠÙ¾ÙĪØ³Øª': 120042,\n",
       " 'ĠRav': 35074,\n",
       " '579': 24847,\n",
       " 'Emitter': 22738,\n",
       " 'tÄĽ': 100521,\n",
       " 'à¥Įà¤ķ': 114650,\n",
       " 'ĠÐ±Ð°ÑĤÑĮÐºÑĸÐ²': 125186,\n",
       " '.clips': 88632,\n",
       " '&Ċ': 80176,\n",
       " '/u': 34666,\n",
       " 'Ġz': 1167,\n",
       " 'Ġdiscrete': 44279,\n",
       " 'buy': 20369,\n",
       " '.jsx': 42040,\n",
       " 'Ġpredetermined': 87010,\n",
       " 'Ġaktar': 114570,\n",
       " 'SharedPointer': 100154,\n",
       " 'glas': 27481,\n",
       " 'Ġcontrary': 26102,\n",
       " 'ä»ĺãģį': 114308,\n",
       " 'åĪĳ': 113293,\n",
       " 'ì°¨': 101532,\n",
       " 'ĠBATCH': 99891,\n",
       " 'ĉurl': 19880,\n",
       " 'omas': 23063,\n",
       " '%-': 44073,\n",
       " '-bedroom': 67967,\n",
       " 'ĠToString': 33228,\n",
       " 'ĠDetail': 26855,\n",
       " '.solve': 70202,\n",
       " 'ĠCharset': 88971,\n",
       " 'ÐµÑĢÑĤÐ°': 126207,\n",
       " 'avn': 31697,\n",
       " 'ĠReplay': 60161,\n",
       " '.Help': 71982,\n",
       " 'Ġcáº£nh': 106642,\n",
       " 'ĠdataSource': 30654,\n",
       " '_ele': 62465,\n",
       " 'ĠBÃĸL': 126775,\n",
       " 'conomic': 32107,\n",
       " 'Ġgrass': 16763,\n",
       " 'Ġshuts': 89678,\n",
       " 'ĠumÃŃst': 113936,\n",
       " 'Ġanchored': 78219,\n",
       " 'ĠÙĤØ±ÙĨ': 123801,\n",
       " '_mtx': 86516,\n",
       " 'ĠbaÄŁlantÄ±lar': 111617,\n",
       " 'luÄŁ': 110013,\n",
       " 'Ð¸ÑĤÐµÐ»ÐµÐ¼': 126568,\n",
       " 'ĠMaiden': 83942,\n",
       " 'Ġevil': 14289,\n",
       " 'ĠChen': 25507,\n",
       " 'ĠLOD': 88063,\n",
       " 'Ġemotional': 14604,\n",
       " 'clf': 70226,\n",
       " 'Ġhuh': 57843,\n",
       " 'à¸µà¹Ģà¸Ń': 124185,\n",
       " 'Ġkas': 48756,\n",
       " 'filter': 5428,\n",
       " 'ĠCOD': 68501,\n",
       " 'Ġbisc': 60559,\n",
       " 'Guardar': 52670,\n",
       " 'Ø´Ø±ÙĥØ©': 125597,\n",
       " 'ĠZum': 72574,\n",
       " 'ĠHP': 12478,\n",
       " 'Ġjich': 124719,\n",
       " '.ResumeLayout': 15905,\n",
       " 'å¾Įãģ®': 123470,\n",
       " 'Owned': 58741,\n",
       " '(savedInstanceState': 15348,\n",
       " 'ĠMonitor': 24423,\n",
       " 'ĠRifle': 48138,\n",
       " 'ĉEntity': 86190,\n",
       " 'æ¬¢': 108025,\n",
       " 'igration': 5141,\n",
       " '\"math': 79228,\n",
       " 'Paragraph': 43265,\n",
       " 'Ġpersonal': 4443,\n",
       " 'Ġtomato': 42120,\n",
       " 'bral': 42743,\n",
       " 'ĠSandwich': 67836,\n",
       " 'ĠRoots': 75687,\n",
       " ',value': 34275,\n",
       " '.confirm': 34505,\n",
       " '_blend': 89620,\n",
       " 'ÑģÐ¸Ð¼': 103815,\n",
       " 'Ġpractical': 15325,\n",
       " '(){Ċ': 3108,\n",
       " 'Ġturist': 117541,\n",
       " 'ĠHDD': 69623,\n",
       " 'çĳ': 103885,\n",
       " '/filter': 64624,\n",
       " 'ãĥ£': 68581,\n",
       " '<|reserved_special_token_140|>': 128148,\n",
       " 'æĤª': 109161,\n",
       " 'Ð¸Ð½Ðµ': 106159,\n",
       " 'ĠBluetooth': 24783,\n",
       " 'ĠRooms': 48403,\n",
       " 'ĠÐ¼ÑĥÐ·Ñĭ': 121996,\n",
       " 'ĠSweet': 27687,\n",
       " 'Ġlanes': 34125,\n",
       " 'Ġventil': 71702,\n",
       " 'Sur': 23912,\n",
       " 'Ġusing': 1701,\n",
       " 'Market': 39922,\n",
       " 'licht': 38733,\n",
       " 'Î¯Î¿Ïħ': 102524,\n",
       " 'ĠSomehow': 80147,\n",
       " 'Ps': 21051,\n",
       " 'Ġcancers': 51423,\n",
       " 'ÙıØ¹': 127640,\n",
       " '.assertTrue': 15659,\n",
       " 'Ġnoch': 18268,\n",
       " '(port': 21924,\n",
       " 'Ġrien': 55455,\n",
       " 'ĠFabric': 37407,\n",
       " 'ĠElf': 44700,\n",
       " 'Ġreceptors': 44540,\n",
       " 'ĠJObject': 66469,\n",
       " 'typeName': 86591,\n",
       " 'opr': 47388,\n",
       " 'ĠÎºÏħ': 108691,\n",
       " 'ability': 2968,\n",
       " 'ĉport': 53357,\n",
       " 'ä¾¯': 120580,\n",
       " 'zone': 8855,\n",
       " 'Ġjente': 73504,\n",
       " 'ĠØ³ÙĨÚ¯': 102102,\n",
       " 'ØªØ±': 100337,\n",
       " 'ĠãĥĿ': 117082,\n",
       " 'ĠSMA': 96996,\n",
       " 'SPELL': 43960,\n",
       " '_zip': 43231,\n",
       " '_f': 766,\n",
       " 'edith': 82163,\n",
       " 'dÃ¼ÄŁÃ¼': 114437,\n",
       " 'à¸£à¸²à¸¢à¸ĩà¸²à¸Ļ': 127304,\n",
       " 'wj': 68054,\n",
       " '-click': 29218,\n",
       " '.erb': 74866,\n",
       " '_scal': 29756,\n",
       " 'Ã¶rper': 76124,\n",
       " 'wife': 48841,\n",
       " 'ĠmÃ¡te': 119148,\n",
       " 'Ġsubjective': 44122,\n",
       " 'ĠTá»īnh': 118879,\n",
       " 'Ã¼ph': 112379,\n",
       " '.Organization': 95148,\n",
       " 'Â·Â·Â·Â·': 127971,\n",
       " 'Ġinherit': 24683,\n",
       " '-expanded': 31136,\n",
       " 'ansen': 61965,\n",
       " 'translated': 54342,\n",
       " 'ordinates': 8916,\n",
       " 'à¸ģà¸İ': 116715,\n",
       " 'weg': 29229,\n",
       " 'ĠHIGH': 38717,\n",
       " 'Ġ[_': 15484,\n",
       " 'Ġorm': 68702,\n",
       " 'getResource': 35660,\n",
       " 'Ġsak': 78410,\n",
       " 'Ġrisult': 89212,\n",
       " 'ĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠ': 1961,\n",
       " 'anca': 64345,\n",
       " '.Time': 16698,\n",
       " 'ĠmockMvc': 97442,\n",
       " 'omy': 5650,\n",
       " 'Ġespecific': 69694,\n",
       " 'paragus': 94789,\n",
       " 'ãĥ¼ãĥĵãĤ¹': 121098,\n",
       " 'Ġpian': 60166,\n",
       " 'Ġmise': 57459,\n",
       " 'Î¹ÏĥÏĦÎ¿': 122974,\n",
       " 'Ġà¤īà¤®': 108284,\n",
       " 'Ġfunktion': 69412,\n",
       " 'Ġláº¯p': 112632,\n",
       " 'ĠMate': 44670,\n",
       " 'Ġlikewise': 39022,\n",
       " 'mana': 48576,\n",
       " 'ĠnecessÃ¡rio': 96644,\n",
       " 'ĠÐ¿Ð¾Ð»ÑĮ': 118839,\n",
       " 'Claim': 46644,\n",
       " 'Ġaltijd': 88869,\n",
       " 'ĠÐ¡Ð°Ð½': 114736,\n",
       " 'jen': 24041,\n",
       " 'ĠÐ¼ÑĥÐ¶ÑĩÐ¸Ð½': 126772,\n",
       " 'ãģŁãĤī': 127567,\n",
       " 'Ġmutating': 97618,\n",
       " 'anganese': 66964,\n",
       " 'jong': 99560,\n",
       " '015': 16037,\n",
       " 'ĠKUR': 123386,\n",
       " 'ĠsmÄĽ': 106262,\n",
       " 'Ġgroupe': 57951,\n",
       " 'olumn': 1309,\n",
       " 'skÃ½ch': 103052,\n",
       " 'ÎŃÏģÎµÎ¹': 114695,\n",
       " '_after': 20434,\n",
       " '_SHIFT': 23487,\n",
       " 'Ġbureaucracy': 64931,\n",
       " '_TIM': 17163,\n",
       " '(\"/\");Ċ': 59523,\n",
       " 'Ġareas': 5789,\n",
       " 'Ġfrancaise': 67568,\n",
       " 'thag': 96462,\n",
       " 'ĠSearches': 82269,\n",
       " 'ÏĦÎŃÎ»Îµ': 123689,\n",
       " 'ĠTerm': 17978,\n",
       " '.Threading': 7653,\n",
       " 'lasses': 34968,\n",
       " 'ï¼ı/': 124687,\n",
       " 'ACCEPT': 98456,\n",
       " '942': 20249,\n",
       " 'Ġadvancing': 44169,\n",
       " 'Ġlangu': 83400,\n",
       " 'ÏĦÎ¹ÎºÎ¬': 103643,\n",
       " 'SEP': 82476,\n",
       " '_TLS': 70167,\n",
       " 'Ð³Ð»ÑıÐ´': 105144,\n",
       " 'Ġhottest': 38391,\n",
       " 'ĠåĮĹäº¬': 110536,\n",
       " '.into': 40960,\n",
       " 'acular': 23868,\n",
       " '.or': 25268,\n",
       " '_editor': 34852,\n",
       " 'Ġruled': 21989,\n",
       " '.\"\"': 11371,\n",
       " 'Ġantagonist': 82159,\n",
       " 'Ġerotic': 34416,\n",
       " 'oxide': 55189,\n",
       " 'ful': 1285,\n",
       " 'ĠÐºÐ¾ÑĪ': 107763,\n",
       " '673': 24938,\n",
       " 'ĠYine': 126704,\n",
       " 'Ġcorrel': 35983,\n",
       " '.Load': 14296,\n",
       " '.FormBorderStyle': 46214,\n",
       " 'ĠReload': 57441,\n",
       " 'Ġhass': 37504,\n",
       " 'ĠØ§Ø¸': 125807,\n",
       " 'à¸±à¸ļà¸ªà¸Ļ': 121196,\n",
       " 'ĠPacks': 90632,\n",
       " '_use': 16330,\n",
       " 'Ġteor': 115256,\n",
       " 'ĠparamInt': 41850,\n",
       " 'Ġoggi': 89744,\n",
       " '_err': 9450,\n",
       " '_aff': 50014,\n",
       " 'éĻ°': 127122,\n",
       " 'ÐłÑĳ': 122824,\n",
       " 'ÙıÙħ': 106715,\n",
       " '>čĊčĊ': 10605,\n",
       " 'lrt': 56968,\n",
       " 'uplicate': 14399,\n",
       " 'ĠLindsey': 65379,\n",
       " '....ĊĊ': 20838,\n",
       " 'Ġclutter': 54916,\n",
       " 'seite': 62165,\n",
       " 'unga': 92945,\n",
       " 'ĠToe': 90904,\n",
       " 'ĠEc': 37211,\n",
       " '-national': 75629,\n",
       " 'ĠSherman': 52983,\n",
       " 'SENS': 61287,\n",
       " 'éľĢ': 59462,\n",
       " 'ĠHeal': 82130,\n",
       " 'acht': 16317,\n",
       " '_MAG': 56331,\n",
       " 'Shutdown': 63104,\n",
       " 'ĠPARA': 51500,\n",
       " 'Âłob': 124531,\n",
       " 'Ġontvangst': 51390,\n",
       " 'ĠÐ²Ð¸Ð´': 74020,\n",
       " 'ĠØ¨Ø±ÙĤ': 121594,\n",
       " '<|reserved_special_token_85|>': 128093,\n",
       " 'åľ°åįĢ': 122693,\n",
       " 'space': 8920,\n",
       " 'Ø§Øµ': 100905,\n",
       " 'ovny': 119430,\n",
       " 'Ġì§Ħì§ľ': 118769,\n",
       " 'affected': 32157,\n",
       " 'eel': 96551,\n",
       " 'lington': 43747,\n",
       " 'ĠmView': 54685,\n",
       " 'HTMLElement': 64957,\n",
       " '(blank': 58962,\n",
       " 'æĸ°å¢ŀ': 94720,\n",
       " 'Ġaffluent': 81879,\n",
       " 'Ġattraction': 33464,\n",
       " 'Ġintertwined': 99892,\n",
       " 'ĠHonor': 43044,\n",
       " 'è®°': 41914,\n",
       " '(Data': 19495,\n",
       " \"Ġ']\": 43977,\n",
       " 'ĠÅĻÃ¡d': 115008,\n",
       " 'è·Ł': 104142,\n",
       " 'ï½ŀĊĊ': 100065,\n",
       " 'ĠÐ·Ð°Ð²Ð¶Ð´Ð¸': 113447,\n",
       " 'Ã¼ndeki': 121277,\n",
       " 'ĠQUERY': 68235,\n",
       " 'mayan': 111216,\n",
       " 'ĉĉĉĉĉĠĠĠĠ': 58754,\n",
       " 'ĠResponsibilities': 74112,\n",
       " 'Ġsouvenir': 98395,\n",
       " 'Ġsuspense': 72930,\n",
       " '.recipe': 62506,\n",
       " '.Media': 20351,\n",
       " 'ĠÑĪ': 55617,\n",
       " 'Ġornaments': 85368,\n",
       " 'Ordered': 55484,\n",
       " 'iflower': 77873,\n",
       " 'ĠbÄĽhem': 108893,\n",
       " 'ĠDavidson': 54345,\n",
       " 'Ġarticles': 9908,\n",
       " '_WORK': 35144,\n",
       " '.count': 6637,\n",
       " '\\\\Mail': 78232,\n",
       " 'Ġfarmhouse': 83408,\n",
       " 'ĠvyÅ¡Å¡ÃŃ': 115609,\n",
       " 'Ġsurprise': 13051,\n",
       " 'ĠCommun': 57298,\n",
       " 'Ġfaiz': 122656,\n",
       " 'Ġpanc': 54574,\n",
       " '-po': 75488,\n",
       " 'ĠÙĤØ¯Ùħ': 111193,\n",
       " 'reffen': 65360,\n",
       " '.GetObject': 26700,\n",
       " '.TextChanged': 68152,\n",
       " 'ensor': 3890,\n",
       " 'ĠPremier': 20210,\n",
       " 'Ġblueprint': 54029,\n",
       " 'Ġembryos': 89873,\n",
       " '105': 6550,\n",
       " 'ÏģÏİ': 103006,\n",
       " 'nict': 106489,\n",
       " 'Å¡ek': 110613,\n",
       " 'ĠApproved': 52175,\n",
       " 'ĠScientology': 71085,\n",
       " 'Ġbasics': 32874,\n",
       " '445': 19697,\n",
       " '/post': 31096,\n",
       " 'beg': 52253,\n",
       " 'emann': 80998,\n",
       " 'ĠFarmers': 63422,\n",
       " 'ĠBindingFlags': 59778,\n",
       " 'ication': 20901,\n",
       " \"']},Ċ\": 98164,\n",
       " 'Ġwindy': 94021,\n",
       " 'Ð½Ð¸ÑĤÐµÐ»ÑĮ': 106089,\n",
       " 'styled': 23696,\n",
       " '.BadRequest': 54892,\n",
       " 'faq': 46623,\n",
       " 'ĠespaÃ±': 50475,\n",
       " 'Ġ)ĊĊ': 5235,\n",
       " 'had': 32345,\n",
       " 'ĠDisclaimer': 67929,\n",
       " '#elif': 29949,\n",
       " '-Ð¿ÑĢÐ°Ð²': 126727,\n",
       " 'ĠGingrich': 87493,\n",
       " 'ĠNano': 64051,\n",
       " 'ãĤĬãģ®': 111331,\n",
       " 'Ġminimum': 8187,\n",
       " 'ĠrÃ³wnieÅ¼': 68841,\n",
       " 'ÛĮØ¯ÙĨ': 118093,\n",
       " 'ĠÎłÎ±Ïģ': 124319,\n",
       " 'ĠÐºÐ¾ÑĤÐ¾ÑĢ': 38153,\n",
       " 'à¹Ģà¸ĺ': 109457,\n",
       " '_TEMPLATE': 35886,\n",
       " 'Ġå¼Ģ': 83047,\n",
       " '\"]čĊ': 48122,\n",
       " '(^)(': 99785,\n",
       " 'à¹Ģà¸£': 100561,\n",
       " 'ãģ¾ãģŁ': 53900,\n",
       " 'Ġ((': 1819,\n",
       " 'hoe': 77035,\n",
       " 'åĽ²': 116310,\n",
       " 'printed': 53313,\n",
       " 'ĠØ¨Ø¯Ø§ÙĨ': 125224,\n",
       " 'chair': 35296,\n",
       " 'ĠÄĳoÃłn': 106781,\n",
       " '.mode': 23841,\n",
       " 'ĠÐ±ÑĥÐ»Ð¾': 102651,\n",
       " '_routes': 65414,\n",
       " 'addir': 45625,\n",
       " 'Ġffm': 76992,\n",
       " 'Ġtrek': 45688,\n",
       " \"Ġ'-')Ċ\": 91196,\n",
       " 'Ġpenn': 44049,\n",
       " 'Ġverification': 23751,\n",
       " 'Ġobserv': 9466,\n",
       " 'obuf': 18971,\n",
       " 'igram': 50227,\n",
       " '_bold': 96777,\n",
       " 'ĠÃ¼lke': 115864,\n",
       " 'ILA': 98596,\n",
       " 'çŃī': 50667,\n",
       " 'ĠLights': 35270,\n",
       " '/layouts': 90217,\n",
       " 'cies': 70107,\n",
       " 'ioxide': 37901,\n",
       " 'Ġproyecto': 50951,\n",
       " 'ĠSharma': 61115,\n",
       " 'ĠWeg': 59634,\n",
       " '(bt': 69517,\n",
       " 'olarity': 73627,\n",
       " 'ethereum': 68222,\n",
       " '<thead': 59267,\n",
       " '.panel': 9924,\n",
       " 'andre': 80281,\n",
       " 'Ġgave': 6688,\n",
       " 'ĠØ¯ÙĨÛĮØ§': 119032,\n",
       " 'åį·': 103012,\n",
       " 'Hal': 57041,\n",
       " 'Ġglaring': 72221,\n",
       " '_required': 19265,\n",
       " 'ANGES': 71894,\n",
       " 'Opp': 56851,\n",
       " 'è²Į': 126325,\n",
       " 'Ġcrushed': 33745,\n",
       " 'Ġeksik': 116419,\n",
       " 'frag': 34298,\n",
       " 'ĠdiseÃ±o': 84908,\n",
       " 'iá»ĩc': 100684,\n",
       " 'Ġwarriors': 43600,\n",
       " 'queryString': 96988,\n",
       " '/cmd': 84133,\n",
       " '.habbo': 79358,\n",
       " 'Ġwarns': 49140,\n",
       " 'Ġmeats': 63875,\n",
       " '(zone': 75328,\n",
       " 'd': 67,\n",
       " 'estruct': 30394,\n",
       " 'Ġà¹ĥà¸«': 110830,\n",
       " '.addChild': 32869,\n",
       " 'ĠìĿ¸ìłķ': 127507,\n",
       " 'Ġstigma': 60381,\n",
       " 'éº': 102267,\n",
       " 'ãĥ¬ãĥ³': 111999,\n",
       " '.getLogger': 13993,\n",
       " 'Ð¾Ð½Ð°Ð»ÑĮ': 101811,\n",
       " 'Ġtread': 48814,\n",
       " 'Anthony': 70098,\n",
       " 'Ġado': 56285,\n",
       " 'ĠProv': 59429,\n",
       " 'ĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĠĊ': 97117,\n",
       " 'ĠìŀĪìĿĦ': 109077,\n",
       " 'angers': 14381,\n",
       " '.hstack': 78601,\n",
       " '.per': 12211,\n",
       " 'Ġhearing': 11011,\n",
       " 'emachine': 99569,\n",
       " 'Ġthou': 34223,\n",
       " 'vasive': 78134,\n",
       " 'Ã¼ltÃ¼r': 106975,\n",
       " 'ÑĩÐ¸ÑĤÑĮ': 121784,\n",
       " 'ĠØªØ¹Ø±ÛĮÙģ': 124751,\n",
       " '_gc': 50523,\n",
       " 'Ġafs': 67813,\n",
       " 'Ġwood': 7732,\n",
       " 'ĠxAxis': 62285,\n",
       " 'ĠÙ¾ÛĮÚĨ': 127602,\n",
       " '-con': 15204,\n",
       " 'ĠMN': 36095,\n",
       " 'ĠzajÃŃmav': 118799,\n",
       " 'Ġshark': 44892,\n",
       " 'ĠFolding': 92250,\n",
       " 'platz': 58648,\n",
       " 'ĠcomponentWillUnmount': 72676,\n",
       " 'Ð»ÑıÑħ': 107209,\n",
       " 'Ġvoir': 46131,\n",
       " \"'all\": 65948,\n",
       " '-primary': 9999,\n",
       " 'UniformLocation': 52804,\n",
       " '.camel': 97423,\n",
       " 'ĠDit': 53518,\n",
       " 'Later': 31082,\n",
       " 'ĠSOCK': 35651,\n",
       " 'Qualifier': 84591,\n",
       " 'Buffer': 4187,\n",
       " 'ed': 291,\n",
       " 'Ġreporters': 19578,\n",
       " 'pletely': 50268,\n",
       " 'Up': 2378,\n",
       " 'Ġpem': 55284,\n",
       " 'Ġrounding': 52662,\n",
       " 'ĠYellowstone': 96179,\n",
       " '\\\\Helpers': 95663,\n",
       " 'Ġre': 312,\n",
       " 'Ġtalked': 15243,\n",
       " '-message': 30432,\n",
       " 'Ġà¸¥': 102386,\n",
       " 'Ġconserve': 78548,\n",
       " 'umbnail': 11272,\n",
       " 'ĠCheap': 37034,\n",
       " 'ĠDer': 13031,\n",
       " 'Secret': 20357,\n",
       " 'ĠactionBar': 90236,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The vocabulary maps subwords to integers <span style='color: grey'>(here, out of 128k possibilities)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6151"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['hi'] # happens to be a token here, although is not guaranteed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Encoding** is the process of obtaining the sequence of tokens<br/>\n",
    "<span style='color:grey'>(<a href=\"https://belladoreai.github.io/llama-tokenizer-js/example-demo/build/\">llama-tokenizer.js</a> is great for visualizing this)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5963, 2065, 3187, 925]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_string = tokenizer.encode('tokenization example string', add_special_tokens=False)\n",
    "encoded_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding** is the process of obtaining the string from tokens<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'ization', 'Ġexample', 'Ġstring']\n",
      "tokenization example string\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoded_string))\n",
    "print(tokenizer.decode(encoded_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, let's look at the model. It mostly has components we've seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Querying for generations\n",
    "\n",
    "+ Given the tokenizer and model, and input token sequence $x_{1:n}=[x_1, \\ldots, x_n]$,\n",
    "we can ask the model to predict (generate) next tokens $P(x_{n+j}|x_{1:n+j-1})$.\n",
    "+ The model can sample from many possible generations <br/>\n",
    "  <span style='color: grey'>(often controlled by `temperature`, as well as top-$p$ and top-$k$ parameters)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Once upon a time, there was a small town in Africa where the\n",
      "<|begin_of_text|>Once upon a time, there was a young man named Max. Max\n",
      "<|begin_of_text|>Once upon a time, in the land of Aethoria, there\n",
      "<|begin_of_text|>Once upon a time, a beautiful and mysterious woman named Lena wandered into\n",
      "<|begin_of_text|>Once upon a time, in a small village nestled in the rolling hills\n",
      "<|begin_of_text|>Once upon a time, in a bustling city, a young and ambitious\n",
      "<|begin_of_text|>Once upon a time, there lived a little girl named Lily who had\n",
      "<|begin_of_text|>Once upon a time, there was a boy named Max who lived in\n",
      "<|begin_of_text|>Once upon a time, in a small village nestled in the rolling hills\n",
      "<|begin_of_text|>Once upon a time, there lived a young girl named Sophia. Sophia\n"
     ]
    }
   ],
   "source": [
    "prompt_str = 'Once upon a time'\n",
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "\n",
    "num_samples = 10\n",
    "outputs = []\n",
    "for _ in range(num_samples):\n",
    "    model_output_tokens = model.generate(\n",
    "        prompt_tokens, do_sample=True, temperature=1.0, max_new_tokens=10,\n",
    "        pad_token_id=tokenizer.eos_token_id, \n",
    "        attention_mask = torch.ones_like(prompt_tokens),\n",
    "    ).squeeze(0)\n",
    "    model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "    outputs.append(model_output_str)\n",
    "\n",
    "for output in outputs:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generations for answering questions\n",
    "\n",
    "With the ability to predict next tokens, we can query the model to answer questions.\n",
    "This is an example from the standard [MMLU benchmark](https://huggingface.co/datasets/cais/mmlu)\n",
    "along with a basic prompt style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
    "\n",
    "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
    "\n",
    "A: Aristotle\n",
    "B: John Locke\n",
    "C: Socrates\n",
    "D: Plato\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
      "\n",
      "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
      "\n",
      "A: Aristotle\n",
      "B: John Locke\n",
      "C: Socrates\n",
      "D: Plato\n",
      "\n",
      "Answer: C\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "\n",
    "model_output_tokens = model.generate(\n",
    "    prompt_tokens, do_sample=False, temperature=None, max_new_tokens=1,\n",
    "    pad_token_id=tokenizer.eos_token_id, attention_mask=torch.ones_like(prompt_tokens)\n",
    ").squeeze(0)\n",
    "model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "print(model_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extracting more information\n",
    "\n",
    "+ The model's generation was correct, but doesn't tell us much\n",
    "+ **Chain-of-thought** prompting is a way of extracting more information,\n",
    "  as done in <a href=\"https://arxiv.org/abs/2205.11916\">Large Language Models are Zero-Shot Reasoners</a>.\n",
    "+ Many variations on this:\n",
    "\n",
    "<center>\n",
    "<img width='70%' src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0EFaLY_NIIDkDn3vP-FBmQ.png\"> <br/>\n",
    "<a href=\"https://arxiv.org/abs/2308.09687\">Source: Graph of Thoughts</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
    "\n",
    "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
    "\n",
    "A: Aristotle\n",
    "B: John Locke\n",
    "C: Socrates\n",
    "D: Plato\n",
    "\n",
    "Answer: Let's think step-by-step. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
      "\n",
      "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
      "\n",
      "A: Aristotle\n",
      "B: John Locke\n",
      "C: Socrates\n",
      "D: Plato\n",
      "\n",
      "Answer: Let's think step-by-step.  The quote is attributed to Socrates.  Socrates was a Greek philosopher who lived in ancient Athens.  He is known for his method of questioning, which is now called the Socratic method.  Socrates believed that the unexamined life is not worth living, and this quote reflects his belief that one must examine their own life and values in order to live a meaningful and fulfilling life.  Therefore, the correct answer is C.  The other options are incorrect because Aristotle was a philosopher\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "\n",
    "model_output_tokens = model.generate(\n",
    "    prompt_tokens, do_sample=False, temperature=None, max_new_tokens=100,\n",
    "    pad_token_id=tokenizer.eos_token_id, attention_mask=torch.ones_like(prompt_tokens)\n",
    ").squeeze(0)\n",
    "model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "print(model_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From next-token predictions to a chatbot\n",
    "\n",
    "+ Now that we can generate continuations of sequences, what if we want to chat with the LLM as an assistant or chatbot?\n",
    "+ We can't just query it as we were doing before ❌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|>What food do you recommend me? I'm looking for something that's easy to make\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_str = 'What food do you recommend me?'\n",
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "model_output_tokens = model.generate(\n",
    "    prompt_tokens, do_sample=False, temperature=None, max_new_tokens=10,\n",
    "    pad_token_id=tokenizer.eos_token_id, attention_mask=torch.ones_like(prompt_tokens)\n",
    ").squeeze(0)\n",
    "model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "model_output_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to use a special **chat prompt template** that the model has been trained with on other chat data. These usually separate the text into `system`, `user`, and `assistant` roles and formats them back into a standardized sequence of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 868, 4723, 220, 2366, 19, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 3923, 3691, 656, 499, 7079, 757, 30, 128009, 128006, 78191, 128007, 271]]\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 15 Nov 2024\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What food do you recommend me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "  {\"role\": \"user\", \"content\": \"What food do you recommend me?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(prompt, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True,).to(device)\n",
    "print(inputs['input_ids'].tolist()); print()\n",
    "print(tokenizer.decode(inputs['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's run the generation on this input and look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 15 Nov 2024\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What food do you recommend me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'd be happy to recommend some delicious food options for you. Since I don't know your personal preferences, I'll provide a variety of suggestions.\n",
      "\n",
      "Here are some popular and tasty food ideas:\n",
      "\n",
      "**Breakfast Options:**\n",
      "\n",
      "1. Avocado toast with scrambled eggs and cherry tomatoes\n",
      "2. Greek\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs, do_sample=False, temperature=None,\n",
    "    max_new_tokens=60, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code generation\n",
    "\n",
    "Lastly, let's switch to some basic code generation with Code Llama. We will load a quantized version for speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab817d35b9e64b0bb09605e1f949f8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840810a9328f4b99bd05075d2bb2cc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "del tokenizer # now is inside the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/CodeLlama-7B-GGUF\", model_file=\"codellama-7b.Q2_K.gguf\", model_type=\"llama\", gpu_layers=0,\n",
    "    max_new_tokens=50, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(top_k=40, top_p=0.95, temperature=0.1, repetition_penalty=1.1, last_n_tokens=64, seed=-1, batch_size=8, threads=-1, max_new_tokens=50, stop=None, stream=False, reset=True, context_length=-1, gpu_layers=0, mmap=True, mlock=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For simple completions, the prompt can be the same as before with the start of a block of code.\n",
    "This is an example from the standard [humanevalplus](https://huggingface.co/datasets/evalplus/humanevalplus)\n",
    "dataset and benchmark. We can look at the tokenization in the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 29871, 13, 1753, 18755, 29898, 29876, 29901, 938, 1125, 13, 1678, 9995, 11609, 302, 29899, 386, 383, 747, 265, 21566, 1353, 29889, 13, 1678, 8653, 18755, 29898, 29896, 29900, 29897, 13, 268, 29945, 29945, 13, 1678, 8653, 18755, 29898, 29896, 29897, 13, 268, 29896, 13, 1678, 8653, 18755, 29898, 29947, 29897, 13, 268, 29906, 29896, 13, 1678, 9995, 13]\n"
     ]
    }
   ],
   "source": [
    "prompt_str = '''\n",
    "def fib(n: int):\n",
    "    \"\"\"Return n-th Fibonacci number.\n",
    "    >>> fib(10)\n",
    "    55\n",
    "    >>> fib(1)\n",
    "    1\n",
    "    >>> fib(8)\n",
    "    21\n",
    "    \"\"\"\n",
    "'''\n",
    "print(model.tokenize(prompt_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And query the model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    if n < 2:\n",
      "        return n\n",
      "    else:\n",
      "        return fib(n-1) + fib(n-2)\n",
      "\n",
      "def test_fib():\n",
      "    assert fib(1) == 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model(prompt_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From code completion to infilling\n",
    "\n",
    "+ Completion works great and is powerful, but what if we want to generate suggestions in the middle of a larger file?\n",
    "+ **How do we prompt the model in the middle of the code??**\n",
    "\n",
    "---\n",
    "\n",
    "```Python\n",
    "def fib(n: int):\n",
    "    \"\"\"Return n-th Fibonacci number.\n",
    "    >>> fib(10)\n",
    "    55\n",
    "    >>> fib(1)\n",
    "    1\n",
    "    >>> fib(8)\n",
    "    21\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        ## user's cursor is here ##\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Infilling and fill-in-the-middle (FIM) prompting\n",
    "\n",
    "+ Think about the file consisting of `PREFIX`, `MIDDLE`, and `SUFFIX` portions\n",
    "+ **Key idea:** reformulate the prompt so the middle comes at the end,\n",
    "  so a file is represented as `<PRE> prefix <SUF>suffix <MID>middle`\n",
    "  + Uses special tokens `<PRE>` `<MID>` and `<SUF>` to separate them\n",
    "  + ⚠ **Need to be very careful with the spaces**\n",
    "+ More details in [Efficient Training of Language Models to Fill in the Middle](https://arxiv.org/abs/2207.14255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's what the basic FIM prompt tokenizes to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 32007, 775, 32008, 401, 32009]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = model.tokenize('<PRE> code <SUF>code <MID>')\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', ' <PRE>', ' code', ' <SUF>', 'code', ' <MID>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.detokenize([tok]) for tok in toks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can put the Fibonacci prompt into this format and ask for the middle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return n <EOT>\n"
     ]
    }
   ],
   "source": [
    "prompt_str = '''<PRE> def fib(n: int):\n",
    "    \"\"\"Return n-th Fibonacci number.\n",
    "    >>> fib(10)\n",
    "    55\n",
    "    >>> fib(1)\n",
    "    1\n",
    "    >>> fib(8)\n",
    "    21\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "         <SUF>\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2) <MID>'''\n",
    "print(model(prompt_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/cornell_tech2.svg\"></left>\n",
    "\n",
    "# Summary\n",
    "1. Tour through my favorite introductory parts from them\n",
    "2. Some code examples to show how to apply and use <br/>\n",
    "    a) **basic tokenization** and **autoregressive generation**, <br/>\n",
    "    b) **chat templates**, and <br/>\n",
    "    c) **code completion** (fill-in-the-middle)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "neural-ode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "rise": {
   "controlsTutorial": false,
   "height": 900,
   "help": false,
   "margin": 0,
   "maxScale": 2,
   "minScale": 0.2,
   "progress": true,
   "scroll": true,
   "theme": "simple",
   "width": 1200
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
